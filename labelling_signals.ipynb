{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0IbhO1zy4F5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import pathlib\n",
        "import peakutils\n",
        "from BaselineRemoval import BaselineRemoval\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "from scipy.io import loadmat, savemat\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "import datetime\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize']=(20,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DK3dJ82y4F8"
      },
      "source": [
        "Labelling EEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnEeSNHuy4GA"
      },
      "outputs": [],
      "source": [
        "def seperate_EEG(marker,EEG_signal):\n",
        "    neutral=marker[marker.event==101]\n",
        "    fear=marker[marker.event==102]\n",
        "    sad=marker[marker.event==103]\n",
        "    happy=marker[marker.event==104]\n",
        "    anger=marker[marker.event==105]\n",
        "    disgust=marker[marker.event==106]\n",
        "    start_neutral=int(neutral['latency'])\n",
        "    end_neutral=int(marker.loc[neutral.index+1,'latency'])\n",
        "    start_fear=int(fear['latency'])\n",
        "    end_fear=int(marker.loc[fear.index+1,'latency'])\n",
        "    start_sad=int(sad['latency'])\n",
        "    end_sad=int(marker.loc[sad.index+1,'latency'])\n",
        "    start_happy=int(happy['latency'])\n",
        "    end_happy=int(marker.loc[happy.index+1,'latency'])\n",
        "    start_anger=int(anger['latency'])\n",
        "    end_anger=int(marker.loc[anger.index+1,'latency'])\n",
        "    start_disgust=int(disgust['latency'])\n",
        "    end_disgust=int(marker.loc[disgust.index+1,'latency'])\n",
        "    n_EEG=EEG_signal[:,start_neutral:end_neutral]\n",
        "    f_EEG=EEG_signal[:,start_fear:end_fear]\n",
        "    s_EEG=EEG_signal[:,start_sad:end_sad]\n",
        "    h_EEG=EEG_signal[:,start_happy:end_happy]\n",
        "    an_EEG=EEG_signal[:,start_anger:end_anger]\n",
        "    d_EEG=EEG_signal[:,start_disgust:end_disgust]\n",
        "    return n_EEG,f_EEG,s_EEG,h_EEG,an_EEG,d_EEG\n",
        "def joining(list):\n",
        "    # Join based on the '-' delimiter\n",
        "    pp = ''.join(str(e) for e in list)\n",
        "    return pp\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adMkFjyLy4GC"
      },
      "outputs": [],
      "source": [
        "files=glob.glob(f\"all_data\\combined_data\\EEG_new1\\*.mat\")\n",
        "for file in files:\n",
        "    EEG=loadmat(file)\n",
        "    marker=pd.DataFrame(EEG['Event_marker'],columns=['event','latency','urevent'])\n",
        "    EEG_signal=EEG['eeg_data']\n",
        "    n_EEG,f_EEG,s_EEG,h_EEG,an_EEG,d_EEG=seperate_EEG(marker,EEG_signal)\n",
        "    EEG_labelled={'neutral':n_EEG,'fear':f_EEG,'sad':s_EEG,'happy':h_EEG,'anger':an_EEG,'disgust':d_EEG}\n",
        "    savemat(r'E:\\multimodal_signal\\all_data\\combined_data\\EEG_labeled\\{}'.format(file[-7:]),EEG_labelled)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT6hAwpSy4GC"
      },
      "source": [
        "Labelling ECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHq-TsFOy4GC"
      },
      "outputs": [],
      "source": [
        "def seperate_ECG(start_pt_ecg,Fs_ECG,Fs_EEG,ECG_signal,marker):\n",
        "    neutral=marker[marker.event==101]\n",
        "    fear=marker[marker.event==102]\n",
        "    sad=marker[marker.event==103]\n",
        "    happy=marker[marker.event==104]\n",
        "    anger=marker[marker.event==105]\n",
        "    disgust=marker[marker.event==106]\n",
        "    start_neutral=int(start_pt_ecg+int(neutral['latency'])*Fs_ECG/Fs_EEG)\n",
        "    end_neutral=int(start_pt_ecg+int(marker.loc[neutral.index+1,'latency'])*Fs_ECG/Fs_EEG)\n",
        "    start_fear=int(start_pt_ecg+int(fear['latency'])*Fs_ECG/Fs_EEG)\n",
        "    end_fear=int(start_pt_ecg+int(marker.loc[fear.index+1,'latency'])*Fs_ECG/Fs_EEG)\n",
        "    start_sad=int(start_pt_ecg+int(sad['latency'])*Fs_ECG/Fs_EEG)\n",
        "    end_sad=int(start_pt_ecg+int(marker.loc[sad.index+1,'latency'])*Fs_ECG/Fs_EEG)\n",
        "    start_happy=int(start_pt_ecg+int(happy['latency'])*Fs_ECG/Fs_EEG)\n",
        "    end_happy=int(start_pt_ecg+int(marker.loc[happy.index+1,'latency'])*Fs_ECG/Fs_EEG)\n",
        "    start_anger=int(start_pt_ecg+int(anger['latency'])*Fs_ECG/Fs_EEG)\n",
        "    end_anger=int(start_pt_ecg+int(marker.loc[anger.index+1,'latency'])*Fs_ECG/Fs_EEG)\n",
        "    start_disgust=int(start_pt_ecg+int(disgust['latency'])*Fs_ECG/Fs_EEG)\n",
        "    end_disgust=int(start_pt_ecg+int(marker.loc[disgust.index+1,'latency'])*Fs_ECG/Fs_EEG)\n",
        "    if start_neutral<0:\n",
        "        start_neutral=0\n",
        "    if start_fear<0:\n",
        "        start_fear=0\n",
        "    if start_sad<0:\n",
        "        start_sad=0\n",
        "    if start_happy<0:\n",
        "        start_happy=0\n",
        "    if start_anger<0:\n",
        "        start_anger=0\n",
        "    if start_disgust<0:\n",
        "        start_neutral=0\n",
        "    n_ECG=ECG_signal[:,start_neutral:end_neutral]\n",
        "    f_ECG=ECG_signal[:,start_fear:end_fear]\n",
        "    s_ECG=ECG_signal[:,start_sad:end_sad]\n",
        "    h_ECG=ECG_signal[:,start_happy:end_happy]\n",
        "    an_ECG=ECG_signal[:,start_anger:end_anger]\n",
        "    d_ECG=ECG_signal[:,start_disgust:end_disgust]\n",
        "    return n_ECG,f_ECG,s_ECG,h_ECG,an_ECG,d_ECG\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lM3AnILry4GF"
      },
      "outputs": [],
      "source": [
        "files=glob.glob(f\"all_data\\combined_data\\ECG_EX\\*.mat\")\n",
        "Experiment_info=pd.read_excel(r\"E:\\multimodal_signal\\all_data\\experiment subjects.xlsx\",sheet_name='experiment')\n",
        "for file in files:\n",
        "\n",
        "    ECG=loadmat(file)\n",
        "    EEG_start=Experiment_info.loc[Experiment_info.ID=='{}'.format(file[-7:-4])].Date\n",
        "    EEG=loadmat(r\"E:\\multimodal_signal\\all_data\\combined_data\\EEG_new1\\{}\".format(file[-7:]))\n",
        "    Fs_EEG=EEG['srate']\n",
        "    marker=pd.DataFrame(EEG['Event_marker'],columns=['event','latency','urevent'])\n",
        "    ECG_data=ECG['ECG']\n",
        "    Fs_ECG=ECG['fs']\n",
        "    start_ECG=ECG['start_time']\n",
        "    EEG_start.index=np.arange(len(EEG_start))\n",
        "    end_ECG=ECG['stop_time']\n",
        "    start=joining(list(start_ECG[0]))\n",
        "    year,month,day,hour,min,sec= int(start[0:4]),int(start[4:6]),int(start[6:8]),int(start[8:10]),int(start[10:12]),int(start[12:14])\n",
        "    date=datetime.datetime(year,month,day,hour,min,sec)\n",
        "    dt=pd.Series(date.strftime('%Y-%m-%d %H:%M:%S'))\n",
        "    delt=pd.to_datetime(dt)-EEG_start #if neg then problem\n",
        "    start_pt_ecg=int(delt[0].total_seconds()*Fs_ECG)\n",
        "    n_ECG,f_ECG,s_ECG,h_ECG,an_ECG,d_ECG=seperate_ECG(start_pt_ecg,Fs_ECG,Fs_EEG,ECG_data,marker)\n",
        "    ECG_labelled={'neutral':n_ECG,'fear':f_ECG,'sad':s_ECG,'happy':h_ECG,'anger':an_ECG,'disgust':d_ECG}\n",
        "    savemat(r'E:\\multimodal_signal\\all_data\\combined_data\\ECG_labelled\\{}'.format(file[-7:]),ECG_labelled)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkOXs_b9y4GG"
      },
      "source": [
        "PPG labelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZImUo5Dy4GH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def seperate_E4(start_pt_ecg,Fs_PPG,Fs_EEG,PPG,marker):\n",
        "    neutral=marker[marker.event==101]\n",
        "    fear=marker[marker.event==102]\n",
        "    sad=marker[marker.event==103]\n",
        "    happy=marker[marker.event==104]\n",
        "    anger=marker[marker.event==105]\n",
        "    disgust=marker[marker.event==106]\n",
        "    start_neutral=int(start_pt_ecg+int(neutral['latency'])*Fs_PPG/Fs_EEG)\n",
        "    end_neutral=int(start_pt_ecg+int(marker.loc[neutral.index+1,'latency'])*Fs_PPG/Fs_EEG)\n",
        "    start_fear=int(start_pt_ecg+int(fear['latency'])*Fs_PPG/Fs_EEG)\n",
        "    end_fear=int(start_pt_ecg+int(marker.loc[fear.index+1,'latency'])*Fs_PPG/Fs_EEG)\n",
        "    start_sad=int(start_pt_ecg+int(sad['latency'])*Fs_PPG/Fs_EEG)\n",
        "    end_sad=int(start_pt_ecg+int(marker.loc[sad.index+1,'latency'])*Fs_PPG/Fs_EEG)\n",
        "    start_happy=int(start_pt_ecg+int(happy['latency'])*Fs_PPG/Fs_EEG)\n",
        "    end_happy=int(start_pt_ecg+int(marker.loc[happy.index+1,'latency'])*Fs_PPG/Fs_EEG)\n",
        "    start_anger=int(start_pt_ecg+int(anger['latency'])*Fs_PPG/Fs_EEG)\n",
        "    end_anger=int(start_pt_ecg+int(marker.loc[anger.index+1,'latency'])*Fs_PPG/Fs_EEG)\n",
        "    start_disgust=int(start_pt_ecg+int(disgust['latency'])*Fs_PPG/Fs_EEG)\n",
        "    end_disgust=int(start_pt_ecg+int(marker.loc[disgust.index+1,'latency'])*Fs_PPG/Fs_EEG)\n",
        "    if start_neutral<0:\n",
        "        start_neutral=0\n",
        "    if start_fear<0:\n",
        "        start_fear=0\n",
        "    if start_sad<0:\n",
        "        start_sad=0\n",
        "    if start_happy<0:\n",
        "        start_happy=0\n",
        "    if start_anger<0:\n",
        "        start_anger=0\n",
        "    if start_disgust<0:\n",
        "        start_neutral=0\n",
        "    n_E4=PPG[start_neutral:end_neutral]\n",
        "    f_E4=PPG[start_fear:end_fear]\n",
        "    n_E4=PPG[start_neutral:end_neutral]\n",
        "    f_E4=PPG[start_fear:end_fear]\n",
        "    s_E4=PPG[start_sad:end_sad]\n",
        "    h_E4=PPG[start_happy:end_happy]\n",
        "    an_E4=PPG[start_anger:end_anger]\n",
        "    d_E4=PPG[start_disgust:end_disgust]\n",
        "    return n_E4,f_E4,s_E4,h_E4,an_E4,d_E4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xZE_OOpy4GI"
      },
      "outputs": [],
      "source": [
        "files=glob.glob(f\"all_data\\combined_data\\E4_data\\*.mat\")\n",
        "Experiment_info=pd.read_excel(r\"E:\\multimodal_signal\\all_data\\experiment subjects.xlsx\",sheet_name='experiment')\n",
        "for file in files:\n",
        "    E4=loadmat(file)\n",
        "    start_time=E4['time']\n",
        "    PPG=E4['ppg']\n",
        "    PPG_Fs=E4['ppg_fs']\n",
        "    Acc=E4['acc']\n",
        "    Acc_fs=E4['acc_fs']\n",
        "    eda=E4['eda']\n",
        "    eda_fs=E4['eda_fs']\n",
        "    hr=E4['hr']\n",
        "    hr_fs=E4['hr_fs']\n",
        "    temp=E4['temp']\n",
        "    temp_fs=E4['temp_fs']\n",
        "    EEG_start=Experiment_info.loc[Experiment_info.ID=='{}'.format(file[-7:-4])].Date\n",
        "    EEG=loadmat(r\"E:\\multimodal_signal\\all_data\\combined_data\\EEG_new1\\{}\".format(file[-7:]))\n",
        "    Fs_EEG=EEG['srate']\n",
        "    marker=pd.DataFrame(EEG['Event_marker'],columns=['event','latency','urevent'])\n",
        "    EEG_start.index=np.arange(len(EEG_start))\n",
        "    delt=pd.to_datetime(start_time)-EEG_start\n",
        "    start_pt_ecg=int(delt[0].total_seconds()*PPG_Fs)\n",
        "    start_pt_acc=int(delt[0].total_seconds()*Acc_fs)\n",
        "    start_pt_eda=int(delt[0].total_seconds()*eda_fs)\n",
        "    start_pt_hr=int(delt[0].total_seconds()*hr_fs)\n",
        "    start_pt_temp=int(delt[0].total_seconds()*temp_fs)\n",
        "    n_PPG,f_PPG,s_PPG,h_PPG,an_PPG,d_PPG=seperate_E4(start_pt_ecg,PPG_Fs,Fs_EEG,PPG,marker)\n",
        "    n_Acc,f_Acc,s_Acc,h_Acc,an_Acc,d_Acc=seperate_E4(start_pt_acc,Acc_fs,Fs_EEG,Acc,marker)\n",
        "    n_eda,f_eda,s_eda,h_eda,an_eda,d_eda=seperate_E4(start_pt_eda,eda_fs,Fs_EEG,eda,marker)\n",
        "    n_hr,f_hr,s_hr,h_hr,an_hr,d_hr=seperate_E4(start_pt_hr,hr_fs,Fs_EEG,hr,marker)\n",
        "    n_temp,f_temp,s_temp,h_temp,an_temp,d_temp=seperate_E4(start_pt_temp,temp_fs,Fs_EEG,temp,marker)\n",
        "    labelled={'neutral_PPG':n_PPG,'fear_PPG':f_PPG,'sad_PPG':s_PPG,'happy_PPG':h_PPG,'anger_PPG':an_PPG,'disgust_PPG':d_PPG,'neutral_Acc':n_Acc,'fear_Acc':f_Acc,'sad_Acc':s_Acc,'happy_Acc':h_Acc,'anger_Acc':an_Acc,'disgust_Acc':d_Acc,'neutral_eda':n_eda,'fear_eda':f_eda,'sad_eda':s_eda,'happy_eda':h_eda,'anger_eda':an_eda,'disgust_eda':d_eda,'neutral_hr':n_hr,'fear_hr':f_hr,'sad_hr':s_hr,'happy_hr':h_hr,'anger_hr':an_hr,'disgust_hr':d_hr,'neutral_temp':n_temp,'fear_temp':f_temp,'sad_temp':s_temp,'happy_temp':h_temp,'anger_temp':an_temp,'disgust_temp':d_temp}\n",
        "\n",
        "    savemat(r'E:\\multimodal_signal\\all_data\\combined_data\\E4_labelled\\{}'.format(file[-7:]),labelled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGPWneCCy4GI"
      },
      "source": [
        "Preprocessing and combining data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX8X9TPOy4GJ"
      },
      "outputs": [],
      "source": [
        "def iir_filter(sig, cutoff, order, btype=\"bandpass\", ftype=\"butter\", fs=512, axis=-1):\n",
        "    sos = signal.iirfilter(order, cutoff, fs=fs, ftype=ftype, btype=btype, output=\"sos\")\n",
        "    y = signal.sosfilt(sos, sig, axis=axis)\n",
        "    return y\n",
        "\n",
        "\n",
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n",
        "def remove_baseline(x, order=None, method=\"imodpoly\"):\n",
        "    if method not in [\"modpoly\", \"imodpoly\", \"zhangfit\"]:\n",
        "        raise Exception(\"Invalid method. Available methods: `modpoly`, `imodpoly`, `zhangfit`\")\n",
        "    if method != \"zhangfit\" and not order:\n",
        "        raise Exception(\"Order must be provided for `modpoly` and `imodpoly` methods\")\n",
        "\n",
        "    base_obj = BaselineRemoval(x)\n",
        "    if method == \"modpoly\":\n",
        "        return base_obj.ModPoly(order)\n",
        "    elif method == \"imodpoly\":\n",
        "        return base_obj.IModPoly(order)\n",
        "    elif method == \"zhangfit\":\n",
        "        return base_obj.ZhangFit()\n",
        "\n",
        "\n",
        "def baseline_correction_polynomial(x: np.ndarray, order: int):\n",
        "    x = (x - x.min()) / (x.max() - x.min())  # Normalize the Signal\n",
        "    p = np.polyfit(np.arange(len(x)), x, order)\n",
        "    f = np.poly1d(p)\n",
        "    baseline = f(np.arange(len(x)))\n",
        "    y = x - baseline\n",
        "    x_amp = x.max() - x.min()\n",
        "    y_amp = y.max() - y.min()\n",
        "    y = y * (x_amp / y_amp)\n",
        "    return y\n",
        "\n",
        "\n",
        "def baseline_correction_als(y, lambda_=10e3, p=0.01, niter=100):\n",
        "    from scipy import sparse\n",
        "    from scipy.sparse.linalg import spsolve\n",
        "\n",
        "    y = (y - y.min()) / (y.max() - y.min())\n",
        "    L = len(y)\n",
        "    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(L, L - 2))\n",
        "    D = lambda_ * D.dot(D.transpose())\n",
        "    w = np.ones(L)\n",
        "    W = sparse.spdiags(w, 0, L, L)\n",
        "    for i in range(niter):\n",
        "        W.setdiag(w)\n",
        "        Z = W + D\n",
        "        z = spsolve(Z, w * y)\n",
        "        w = p * (y > z) + (1 - p) * (y < z)\n",
        "    y = y - z\n",
        "    return y\n",
        "\n",
        "\n",
        "def baseline_correction_svd(x, order):\n",
        "    baseline_values = peakutils.baseline(x)\n",
        "    x = x - baseline_values\n",
        "    return x\n",
        "\n",
        "\n",
        "def moving_average(x, window):\n",
        "    return np.convolve(x, np.ones(window) / window, mode=\"same\")\n",
        "\n",
        "def segmentation(x_data,overlap_rate,time_window,seg_data):\n",
        "\n",
        "    overlap = int((1 - overlap_rate)*time_window)\n",
        "\n",
        "    for i in range(0,len(x_data),overlap):\n",
        "        seg_data.append(x_data[i:i+time_window])\n",
        "    df=pd.DataFrame(seg_data)\n",
        "    df.dropna(inplace=True)\n",
        "    return np.array(df)\n",
        "def bp_filter(x, low_f, high_f, samplerate, plot=False):\n",
        "\n",
        "    low_cutoff_bp = low_f / (samplerate / 2)\n",
        "    high_cutoff_bp = high_f / (samplerate / 2)\n",
        "\n",
        "    [b, a] = signal.butter(5, [low_cutoff_bp, high_cutoff_bp], btype='band')\n",
        "\n",
        "    x_filt = signal.filtfilt(b, a, x)\n",
        "\n",
        "    if plot:\n",
        "        t = np.arange(0, len(x) / samplerate, 1 / samplerate)\n",
        "        plt.plot(t, x)\n",
        "        plt.plot(t, x_filt, 'k')\n",
        "        plt.autoscale(tight=True)\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel('Amplitude (mV)')\n",
        "        plt.show()\n",
        "\n",
        "    return x_filt\n",
        "def plot_signal(x, samplerate, chname):\n",
        "    t = np.arange(0, len(x) / samplerate, 1 / samplerate)\n",
        "    plt.plot(t, x)\n",
        "    plt.autoscale(tight=True)\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Amplitude (mV)')\n",
        "    plt.title(chname)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def notch_filter(x, samplerate, plot=False):\n",
        "    x = x - np.mean(x)\n",
        "\n",
        "    high_cutoff_notch = 48 / (samplerate / 2)\n",
        "    low_cutoff_notch = 51 / (samplerate / 2)\n",
        "\n",
        "    [b, a] = signal.butter(4, [high_cutoff_notch, low_cutoff_notch], btype='stop')\n",
        "\n",
        "    x_filt = signal.filtfilt(b, a, x.T)\n",
        "\n",
        "    if plot:\n",
        "        t = np.arange(0, len(x) / samplerate, 1 / samplerate)\n",
        "        plt.plot(t, x)\n",
        "        plt.plot(t, x_filt.T, 'k')\n",
        "        plt.autoscale(tight=True)\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel('Amplitude (mV)')\n",
        "        plt.show()\n",
        "\n",
        "    return x_filt\n",
        "def segmentation_baseline_correction(x_data,overlap_rate,time_window,seg_data,baseline_order):\n",
        "\n",
        "    overlap = int((1 - overlap_rate)*time_window)\n",
        "\n",
        "    #segment and keep the labels\n",
        "    for i in range(0,len(x_data),overlap):\n",
        "        seg_data.append(baseline_correction_polynomial(x_data[i:i+time_window],order=baseline_order))\n",
        "        #y_segmented_list.append(x_data['activity'][i])\n",
        "    df=pd.DataFrame(seg_data)\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "def resample_signal(sig,initial_fs,target_fs):\n",
        "    resampled_size = int((len(sig) * target_fs) / initial_fs)\n",
        "    resampled = signal.resample(sig, resampled_size)\n",
        "    return resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a28Nbc3y4GL"
      },
      "source": [
        "filter and segment data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_O134Zmy4GL"
      },
      "outputs": [],
      "source": [
        "#functions\n",
        "def PPG_preprocess(PPG,PPG_lf,PPG_hf,PPG_fs,order):\n",
        "    PPG=np.array([i[0] for i in PPG])\n",
        "    PPG_f=bp_filter(PPG,PPG_lf,PPG_hf,PPG_fs)\n",
        "    PPG_baseline_removed=baseline_correction_polynomial(PPG_f,order)\n",
        "    return PPG_baseline_removed\n",
        "\n",
        "def Acc_preprocess(Acc,Acc_lf,Acc_hf,Acc_fs,order):\n",
        "    channels=[]\n",
        "    for i in range(Acc.shape[1]):\n",
        "        ch=Acc[:,i]\n",
        "        Acc_f=bp_filter(ch,Acc_lf,Acc_hf,Acc_fs)\n",
        "        Acc_baseline_removed=baseline_correction_polynomial(Acc_f,order)\n",
        "        channels.append(Acc_baseline_removed)\n",
        "    return pd.DataFrame(channels).T\n",
        "\n",
        "def EEG_preprocess(EEG,EEG_lf,EEG_hf,EEG_fs,order):\n",
        "    channels=[]\n",
        "    for i in range(EEG.shape[1]):\n",
        "        ch=EEG[:,i]\n",
        "        baseline_corrected=baseline_correction_polynomial(ch,order)\n",
        "        x_n=notch_filter(baseline_corrected,EEG_fs,plot=False)  # to filter out power line noise with minimal disruption to the rest of the signal.\n",
        "        filtered=butter_lowpass_filter(x_n, EEG_hf, EEG_fs,order=order)\n",
        "        channels.append(filtered)\n",
        "    return pd.DataFrame(channels).T\n",
        "def ECG_preprocess(ECG,ECG_lf,ECG_hf,ECG_fs,order):\n",
        "    ECG=np.array([i[0] for i in ECG])\n",
        "    ECG_f=bp_filter(ECG,ECG_lf,ECG_hf,ECG_fs)\n",
        "    ECG_n=notch_filter(ECG_f,ECG_fs,plot=False)\n",
        "    ECG_baseline_removed=baseline_correction_polynomial(ECG_n,order)\n",
        "    avg=moving_average(ECG_baseline_removed,10)\n",
        "    return avg\n",
        "def segmentation_channel(x_data,overlap_rate,time_window,ch_list):\n",
        "    for channel in range(x_data.shape[1]):\n",
        "        ch=x_data[:,channel]\n",
        "        #ch_list.append(segmentation(ch,overlap_rate,time_window,seg_data=[]))\n",
        "        ch_list['ch_{}'.format(channel+1)]=segmentation(ch,overlap_rate,time_window,seg_data=[])\n",
        "\n",
        "    return ch_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rL9qwhy6y4GL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "files=glob.glob(f\"all_data\\combined_data\\E4_labelled\\*.mat\")\n",
        "target_fs=128\n",
        "EEG_fs=250\n",
        "ECG_fs=512\n",
        "PPG_fs=64\n",
        "Acc_fs=32\n",
        "Eda_fs=4\n",
        "temp_fs=4\n",
        "hr_fs=1\n",
        "PPG_hf=10\n",
        "PPG_lf=0.5\n",
        "Acc_lf=0.05\n",
        "Acc_hf=10\n",
        "EEG_lf,EEG_hf=(0.2,70)\n",
        "ECG_lf,ECG_hf=(0.2,60)\n",
        "baseline_order=6\n",
        "overlap_rate=0\n",
        "time_win=1024\n",
        "\n",
        "for file in files:\n",
        "    E4=loadmat(file)\n",
        "    EEG_file=loadmat(r'E:\\multimodal_signal\\all_data\\combined_data\\EEG_labeled\\{}.mat'.format(file[-7:-4]))\n",
        "    ECG_file=loadmat(r'E:\\multimodal_signal\\all_data\\combined_data\\ECG_labelled\\{}.mat'.format(file[-7:-4]))\n",
        "    emotions={}\n",
        "    labels=['neutral','fear','anger','sad','happy','disgust']\n",
        "    for label in labels:\n",
        "        PPG=E4['{}_PPG'.format(label)]\n",
        "        Acc=E4['{}_Acc'.format(label)]\n",
        "        Temp=E4['{}_temp'.format(label)]\n",
        "        Eda=E4['{}_eda'.format(label)]\n",
        "        hr=E4['{}_hr'.format(label)]\n",
        "        hr=np.array([i[0] for i in hr])\n",
        "        Eda=np.array([i[0] for i in Eda])\n",
        "        Temp=np.array([i[0] for i in Temp])\n",
        "        EEG=EEG_file[label].T\n",
        "        ECG=ECG_file[label].T\n",
        "        try:\n",
        "            #filter and baseline removal\n",
        "            PPG_filt=PPG_preprocess(PPG,PPG_lf,PPG_hf,PPG_fs,baseline_order)\n",
        "            Acc_filt=Acc_preprocess(Acc,Acc_lf,Acc_hf,Acc_fs,baseline_order)\n",
        "            EEG_filt=EEG_preprocess(EEG,EEG_lf,EEG_hf,EEG_fs,baseline_order)\n",
        "            ECG_filt=ECG_preprocess(ECG,ECG_lf,ECG_hf,ECG_fs,baseline_order)\n",
        "            #resample\n",
        "            resampled_EEG=resample_signal(EEG_filt,EEG_fs,target_fs)\n",
        "            resampled_ECG=resample_signal(ECG_filt,ECG_fs,target_fs)\n",
        "            resampled_PPG=resample_signal(PPG_filt,PPG_fs,target_fs)\n",
        "            resampled_Acc=resample_signal(Acc_filt,Acc_fs,target_fs)\n",
        "            resampled_eda=resample_signal(Eda,Eda_fs,target_fs)\n",
        "            #resampled_hr=resample_signal(hr,hr_fs,target_fs)\n",
        "            resampled_temp=resample_signal(Temp,temp_fs,target_fs)\n",
        "            #segmentation\n",
        "            seg_PPG=segmentation(resampled_PPG,overlap_rate,time_win,seg_data=[])\n",
        "            seg_EEG=segmentation_channel(resampled_EEG,overlap_rate,time_win,ch_list={})\n",
        "            seg_Acc=segmentation_channel(resampled_Acc,overlap_rate,time_win,ch_list={})\n",
        "            seg_ECG=segmentation(resampled_ECG,overlap_rate,time_win,seg_data=[])\n",
        "            seg_Eda=segmentation(resampled_eda,overlap_rate,time_win,seg_data=[])\n",
        "            seg_Temp=segmentation(resampled_temp,overlap_rate,time_win,seg_data=[])\n",
        "            #seg_hr=segmentation(resampled_hr,overlap_rate,time_win,seg_data=[])\n",
        "            emotions['{}'.format(label)]={'ch1_EEG':seg_EEG['ch_1'],'ch2_EEG':seg_EEG['ch_2'],'ch3_EEG':seg_EEG['ch_3'],'ch4_EEG':seg_EEG['ch_4'],'ch5_EEG':seg_EEG['ch_5'],'ch6_EEG':seg_EEG['ch_6'],'ch7_EEG':seg_EEG['ch_7'],'ch8_EEG':seg_EEG['ch_8'],'ch9_EEG':seg_EEG['ch_9'],'ch10_EEG':seg_EEG['ch_10'],'PPG':seg_PPG,'ch1_Acc':seg_Acc['ch_1'],'ch2_Acc':seg_Acc['ch_2'],'ch3_Acc':seg_Acc['ch_3'],'ECG':seg_ECG,'EDA':seg_Eda,'Temp':seg_Temp}\n",
        "            if len(emotions) == 0:\n",
        "                print(file)\n",
        "        except:pass\n",
        "\n",
        "    #if len(emotions)!= 0:\n",
        "        #savemat(r\"E:\\multimodal_signal\\all_data\\combined_data\\multimodal_segmented_data\\{}\".format(file[-7:]),emotions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW80zfaYy4GN"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "#preprocessing.normalize(([seg_EEG['ch_2'][0,:]]))\n",
        "\n",
        "plot_signal(EEG[:,1][:2000],250,'before_preprocess')\n",
        "plot_signal(seg_EEG['ch_2'][0,:],128,'after preprocess')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXhw0b3py4GO"
      },
      "outputs": [],
      "source": [
        "plot_signal(ECG[:4096],512,'before_preprocess')\n",
        "plot_signal(seg_ECG[0,:],128,'after preprocess')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKkE4d7sy4GP"
      },
      "outputs": [],
      "source": [
        "plot_signal(PPG[:510],64,'before_preprocess')\n",
        "plot_signal(seg_PPG[0,:],128,'after preprocess')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiaqSUKdy4GP"
      },
      "outputs": [],
      "source": [
        "plot_signal(Eda[:32],4,'before_preprocess')\n",
        "plot_signal(seg_Eda[0,:],128,'after preprocess')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDm0Xei7y4GQ"
      },
      "outputs": [],
      "source": [
        "types=6\n",
        "\n",
        "Fs=128\n",
        "emotions=[]\n",
        "segmented=[]\n",
        "labels=['neutral', 'fear', 'anger', 'sad', 'happy', 'disgust']\n",
        "dict_labels={'neutral':0, 'fear':1, 'anger':1, 'sad':1, 'happy':2, 'disgust':1}\n",
        "files=glob.glob(r'E:\\multimodal_signal\\all_data\\combined_data\\multimodal_segmented_data\\*')\n",
        "for filename in files:\n",
        "  print(filename)\n",
        "  mat=loadmat(filename)\n",
        "  for label in labels:\n",
        "    try:\n",
        "       PPG=pd.DataFrame(mat[label]['PPG'][0,0])\n",
        "       PPG['label']=dict_labels[label]\n",
        "       PPG['id']=filename[-7:-4]\n",
        "       segmented.append(PPG)\n",
        "    except:pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unsG9OSEy4GQ"
      },
      "outputs": [],
      "source": [
        "ch1_df=pd.concat([segmented[i] for i in range(len(segmented))], axis=0,ignore_index=True)\n",
        "X=np.array(ch1_df.drop(['label','id'],axis=1))\n",
        "Y=np.array(ch1_df.label)\n",
        "Y = Y.reshape((X.shape[0],1))\n",
        "id=np.array(ch1_df.id).reshape(X.shape[0],1)\n",
        "pd.DataFrame(Y).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRkJpiKcy4GR"
      },
      "outputs": [],
      "source": [
        "savemat('PPG_data_for_feature_extract.mat',{'ppg_data':X,'label':Y,'id':id})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biRA4DLHy4GR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}