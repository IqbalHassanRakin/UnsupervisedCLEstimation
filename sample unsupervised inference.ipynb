{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDg5YSCryv6j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import metrics\n",
        "from numpy import load\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.cluster import Birch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BBTsJQSyv6l"
      },
      "outputs": [],
      "source": [
        "url = 'C:/Users/iqbal/Desktop/CogWear/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIp_wu9tyv6t"
      },
      "outputs": [],
      "source": [
        "Xtrain_list = ['load npy files']\n",
        "\n",
        "Ytrain_list = ['load npy files']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t3De9u7yv6w"
      },
      "outputs": [],
      "source": [
        "Xtest_list = ['load npy files']\n",
        "\n",
        "Ytest_list = ['load npy files']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywf_zXoQyv6w"
      },
      "outputs": [],
      "source": [
        "X_train = load(url + Xtrain_list[0])\n",
        "\n",
        "for i in range(len(Xtrain_list) - 1):\n",
        "    data = load(url + Xtrain_list[i + 1])\n",
        "    X_train = np.append(X_train, data, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQZsoKEKyv6z"
      },
      "outputs": [],
      "source": [
        "X_test = load(url + Xtest_list[0])\n",
        "\n",
        "for i in range(len(Xtest_list) - 1):\n",
        "    data = load(url + Xtest_list[i + 1])\n",
        "    X_test = np.append(X_test, data, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXUDKHeQyv61"
      },
      "outputs": [],
      "source": [
        "y_train = load(url + Ytrain_list[0])\n",
        "\n",
        "for i in range(len(Ytrain_list) - 1):\n",
        "    data = load(url + Ytrain_list[i + 1])\n",
        "    y_train = np.append(y_train, data, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmLNn5zKyv62"
      },
      "outputs": [],
      "source": [
        "y_test = load(url + Ytest_list[0])\n",
        "\n",
        "for i in range(len(Ytest_list) - 1):\n",
        "    data = load(url + Ytest_list[i + 1])\n",
        "    y_test = np.append(y_test, data, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckLWo060yv63"
      },
      "outputs": [],
      "source": [
        "y_train = np.select([y_train == 'baseline', y_train == 'cognitive_load'], [0, 1], y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlEYU-F9yv67"
      },
      "outputs": [],
      "source": [
        "y_test = np.select([y_test == 'baseline', y_test == 'cognitive_load'], [0, 1], y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJf7X-nUyv67"
      },
      "outputs": [],
      "source": [
        "Y_train = to_categorical(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIbUoNAYyv68"
      },
      "outputs": [],
      "source": [
        "Y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQva3Shvyv68"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgdZqPALyv68"
      },
      "outputs": [],
      "source": [
        "yt_train = le.fit_transform(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF6OGdgOyv68"
      },
      "outputs": [],
      "source": [
        "yt_test = le.fit_transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm8Jc-_kyv69"
      },
      "source": [
        "# Parameters to test\n",
        "### Number of Features: 64, 128, 256\n",
        "### Number of Epochs: 10, 20\n",
        "### Batch Size: 30, 60\n",
        "### Number of Clusters: 2, 4, 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hVWUdUwyv7A"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HChkqqHXyv7A"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv1D(16, 3, padding='same', activation=tf.keras.layers.LeakyReLU(), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(layers.MaxPool1D(3, strides=2, padding='same'))\n",
        "model.add(layers.Conv1D(32, 3, padding='same', activation=tf.keras.layers.LeakyReLU()))\n",
        "model.add(layers.MaxPool1D(3, strides=2, padding='same'))\n",
        "model.add(layers.Conv1D(64, 3, padding='same', activation=tf.keras.layers.LeakyReLU()))\n",
        "model.add(layers.MaxPool1D(3, strides=2, padding='same'))\n",
        "model.add(layers.Conv1D(128, 3, padding='same', activation=tf.keras.layers.LeakyReLU()))\n",
        "model.add(layers.MaxPool1D(3, strides=2, padding='same'))\n",
        "model.add(layers.Conv1D(256, 3, padding='same', activation=tf.keras.layers.LeakyReLU()))\n",
        "model.add(layers.MaxPool1D(3, strides=2, padding='same'))\n",
        "model.add(layers.Conv1D(512, 3, padding='same', activation=tf.keras.layers.LeakyReLU()))\n",
        "model.add(layers.MaxPool1D(3, strides=2, padding='same'))\n",
        "model.add(layers.Conv1D(256, 3, padding='same', activation=tf.keras.layers.LeakyReLU()))\n",
        "model.add(layers.MaxPool1D(3, strides=2, padding='same'))\n",
        "model.add(layers.Conv1D(128, 3, padding='same', activation=tf.keras.layers.LeakyReLU()))\n",
        "model.add(layers.MaxPool1D(3, strides=2, padding='same'))\n",
        "model.add(layers.Dropout(0.8))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation=tf.keras.layers.LeakyReLU()))\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs = 30, batch_size = 900, validation_data= (X_test, Y_test), callbacks=[tensorboard_callback])\n",
        "\n",
        "feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "features_train_f = feature_extractor.predict(X_train)\n",
        "features_test_f = feature_extractor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD8fIhcPyv7A"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WO7agrMxyv7B"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1xQHpEAyv7D"
      },
      "outputs": [],
      "source": [
        "import tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1anypkBUyv7E"
      },
      "outputs": [],
      "source": [
        "\n",
        "dot_img_file = 'tmp/model_1.png'\n",
        "tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o-Zn_2pyv7F"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "949Z1ShZyv7F"
      },
      "outputs": [],
      "source": [
        "import visualkeras\n",
        "from PIL import ImageFont"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abpbkV7Eyv7G"
      },
      "outputs": [],
      "source": [
        "visualkeras.layered_view(model, legend=True, font=ImageFont.truetype(\"arial.ttf\", 12), draw_volume=True,spacing=30,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgxztX4Xyv7H"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA8wJbQDyv7K"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "un3O84_fyv7M"
      },
      "outputs": [],
      "source": [
        "scaled_features_train = preprocessing.normalize(features_train_f)\n",
        "scaled_features_test = preprocessing.normalize(features_test_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta-cCDYZyv7M"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters = 2)\n",
        "clusters_kmean = kmeans.fit(scaled_features_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhKdbe1Fyv7M"
      },
      "outputs": [],
      "source": [
        "y_pred = kmeans.predict(scaled_features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3tKlZBhyv7N"
      },
      "outputs": [],
      "source": [
        "y_pred_t = 1 - y_pred\n",
        "y_pred = y_pred_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEKSMu3dyv7N"
      },
      "outputs": [],
      "source": [
        "print(f\"Homogeneity: {metrics.homogeneity_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Completeness: {metrics.completeness_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"V-measure: {metrics.v_measure_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Adjusted Rand Index: {metrics.adjusted_rand_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Adjusted Mutual Information: {metrics.adjusted_mutual_info_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Silhouette Coefficient: {metrics.silhouette_score(scaled_features_test, y_pred):.3f}\")\n",
        "print(f\"Inertia: {kmeans.inertia_:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3aUrd0Iyv7O"
      },
      "outputs": [],
      "source": [
        "print(classification_report(yt_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTxBXOkgyv7P"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "\n",
        "class ClusterSimilarityMatrix():\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self._is_fitted = False\n",
        "\n",
        "    def fit(self, y_clusters):\n",
        "        if not self._is_fitted:\n",
        "            self._is_fitted = True\n",
        "            self.similarity = self.to_binary_matrix(y_clusters)\n",
        "            return self\n",
        "\n",
        "        self.similarity += self.to_binary_matrix(y_clusters)\n",
        "\n",
        "    def to_binary_matrix(self, y_clusters):\n",
        "        y_reshaped = np.expand_dims(y_clusters, axis=-1)\n",
        "        return (cdist(y_reshaped, y_reshaped, 'cityblock')==0).astype(int)\n",
        "\n",
        "\n",
        "class EnsembleCustering():\n",
        "    def __init__(self, base_estimators, aggregator, distances=False):\n",
        "        self.base_estimators = base_estimators\n",
        "        self.aggregator = aggregator\n",
        "        self.distances = distances\n",
        "\n",
        "    def fit(self, X):\n",
        "        X_ = X.copy()\n",
        "\n",
        "        clt_sim_matrix = ClusterSimilarityMatrix()\n",
        "        for model in self.base_estimators:\n",
        "            clt_sim_matrix.fit(model.fit_predict(X=X_))\n",
        "\n",
        "        sim_matrix = clt_sim_matrix.similarity\n",
        "        self.cluster_matrix = sim_matrix/sim_matrix.diagonal()\n",
        "\n",
        "        if self.distances:\n",
        "            self.cluster_matrix = np.abs(np.log(self.cluster_matrix + 1e-8)) # Avoid log(0)\n",
        "\n",
        "    def fit_predict(self, X):\n",
        "        self.fit(X)\n",
        "        y = self.aggregator.fit_predict(self.cluster_matrix)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suk7Xq2Gyv7P"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import MiniBatchKMeans, KMeans, SpectralClustering, Birch, BisectingKMeans, AgglomerativeClustering, DBSCAN, MeanShift, OPTICS\n",
        "from scipy.sparse.csgraph import connected_components\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHI9OWpHyv7Q"
      },
      "outputs": [],
      "source": [
        "NUM_KMEANS = 100\n",
        "\n",
        "clustering_models = NUM_KMEANS*[\n",
        "    MiniBatchKMeans(n_clusters=16, n_init=1, max_iter=100)\n",
        "]\n",
        "aggregator_clt = SpectralClustering(n_clusters=2, affinity=\"precomputed\")\n",
        "\n",
        "ens_clt=EnsembleCustering(clustering_models, aggregator_clt)\n",
        "y_ensemble = ens_clt.fit_predict(scaled_features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFT8DJkSyv7Q"
      },
      "outputs": [],
      "source": [
        "y_ensemble = 1 - y_ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zei5a35Ryv7Q"
      },
      "outputs": [],
      "source": [
        "print(f\"Homogeneity: {metrics.homogeneity_score(yt_test, y_ensemble):.3f}\")\n",
        "print(f\"Completeness: {metrics.completeness_score(yt_test, y_ensemble):.3f}\")\n",
        "print(f\"V-measure: {metrics.v_measure_score(yt_test, y_ensemble):.3f}\")\n",
        "print(f\"Adjusted Rand Index: {metrics.adjusted_rand_score(yt_test, y_ensemble):.3f}\")\n",
        "print(f\"Adjusted Mutual Information: {metrics.adjusted_mutual_info_score(yt_test, y_ensemble):.3f}\")\n",
        "print(f\"Silhouette Coefficient: {metrics.silhouette_score(scaled_features_test, y_ensemble):.3f}\")\n",
        "print(f\"Inertia: {kmeans.inertia_:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRzInX3ayv7R"
      },
      "outputs": [],
      "source": [
        "print(classification_report(yt_test, y_ensemble))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNTluHWCyv7R"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "f = AgglomerativeClustering(n_clusters=2, metric='manhattan', linkage='complete')\n",
        "from sklearn.cluster import Birch\n",
        "brc = Birch(threshold=0.6, branching_factor=128, n_clusters=f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEVWmy_Zyv7R"
      },
      "outputs": [],
      "source": [
        "brc.fit(scaled_features_train)\n",
        "y_pred = brc.predict(scaled_features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btA84WxLyv7S"
      },
      "outputs": [],
      "source": [
        "y_pred_t = 1 - y_pred\n",
        "y_pred = y_pred_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n__Ly6Ipyv7T"
      },
      "outputs": [],
      "source": [
        "print(f\"Homogeneity: {metrics.homogeneity_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Completeness: {metrics.completeness_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"V-measure: {metrics.v_measure_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Adjusted Rand Index: {metrics.adjusted_rand_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Adjusted Mutual Information: {metrics.adjusted_mutual_info_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Silhouette Coefficient: {metrics.silhouette_score(scaled_features_test, y_pred):.3f}\")\n",
        "print(f\"Inertia: {kmeans.inertia_:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGlcM51Byv7U"
      },
      "outputs": [],
      "source": [
        "print(classification_report(yt_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1mgl3Qcyv7U"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters = 2, random_state = 0)\n",
        "clusters_kmean = kmeans.fit_predict(scaled_features_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRaTbIiSyv7V"
      },
      "outputs": [],
      "source": [
        "labels = kmeans.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BmrL8Toyv7V"
      },
      "outputs": [],
      "source": [
        "reduced_data = PCA(n_components = 2).fit_transform(scaled_features_train)\n",
        "\n",
        "results = pd.DataFrame(reduced_data, columns=['pca1', 'pca2'])\n",
        "results['label'] = labels\n",
        "\n",
        "sns.scatterplot(x = results.pca1, y = results.pca2, hue = results.label, data = reduced_data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49IlV0Dtyv7V"
      },
      "outputs": [],
      "source": [
        "reduced_data = PCA(n_components = 2).fit_transform(scaled_features_test)\n",
        "\n",
        "results = pd.DataFrame(reduced_data, columns=['pca1', 'pca2'])\n",
        "results['label'] = y_pred\n",
        "\n",
        "sns.scatterplot(x = results.pca1, y = results.pca2, hue = results.label, data = reduced_data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeLY0TtYyv7W"
      },
      "outputs": [],
      "source": [
        "correct_labels = sum(yt == labels)\n",
        "print(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, yt.size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5mTh_S_yv7X"
      },
      "outputs": [],
      "source": [
        "y_pred = labels\n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] != 0:\n",
        "        y_pred[i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw_v2UB8yv7X"
      },
      "outputs": [],
      "source": [
        "correct_labels = sum(yt == y_pred)\n",
        "print(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, yt.size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuOxTu7Hyv7Y"
      },
      "outputs": [],
      "source": [
        "print(f\"Homogeneity: {metrics.homogeneity_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Completeness: {metrics.completeness_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"V-measure: {metrics.v_measure_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Adjusted Rand Index: {metrics.adjusted_rand_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Adjusted Mutual Information: {metrics.adjusted_mutual_info_score(yt_test, y_pred):.3f}\")\n",
        "print(f\"Silhouette Coefficient: {metrics.silhouette_score(scaled_features_test, y_pred):.3f}\")\n",
        "print(f\"Inertia: {kmeans.inertia_:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKOVUl9lyv7Y"
      },
      "outputs": [],
      "source": [
        "print(classification_report(yt_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}